---
title: "EU state of the Union"
output: html_document
date: ""
---

# Library 

```{r}
rm(list = ls())
library(tidyverse)
library(tidytext)
library(wordcloud)
library(topicmodels)
# devtools::install_github("lchiffon/wordcloud2")
# library(wordcloud2)
```

# Loading data 

```{r}
speech_2010 <- read_file("speeches/2010.txt") 
speech_2011 <- read_file("speeches/2011.txt")
speech_2012 <- read_file("speeches/2012.txt") 
speech_2013 <- read_file("speeches/2013.txt") 
speech_2015 <- read_file("speeches/2015.txt")
speech_2016 <- read_file("speeches/2016.txt") 
speech_2017 <- read_file("speeches/2017.txt") 
speech_2018 <- read_file("speeches/2018.txt") 
speech_2020 <- read_file("speeches/2020.txt") 
speech_2021 <- read_file("speeches/2021.txt") 
speech_2022 <- read_file("speeches/2022.txt") 
speech_2023 <- read_file("speeches/2023.txt") 

speeches <- tibble(
  year = c(2010, 2011, 2012, 2013, 2015, 2016, 2017, 2018, 2020, 2021, 2022, 2023),
  text = c(
    speech_2010, speech_2011, speech_2012, speech_2013,
    speech_2015, speech_2016, speech_2017, speech_2018,
    speech_2020, speech_2021, speech_2022, speech_2023))
speeches <- speeches |> 
  mutate(president = case_when(
    year %in% c(2010, 2011, 2012, 2013) ~ "Barroso",
    year %in% c(2015, 2016, 2017, 2018) ~ "Juncker",
    year %in% c(2020, 2021, 2022, 2023) ~ "von der Leyen"))
```

# Working

```{r}
tokenized_speeches <- speeches |> 
  unnest_tokens(word,text, token="words")

stop_words <- stop_words

filtered_speeches <- tokenized_speeches |> 
  anti_join(stop_words, by = "word")
```


```{r}
filtered_speeches |> 
  count(word, sort = TRUE) 

filtered_speeches |> 
  count(word, sort = TRUE) |> 
  filter(n > 100) |>  
  ggplot(aes(n, reorder(word, n))) +
  geom_col() +
  labs(y = NULL)

filtered_speeches |> 
  group_by(president) |> 
  count(word, sort = TRUE) |> 
  slice_head(n = 5)

filtered_speeches |> 
  group_by(year) |> 
  count(word, sort = TRUE) |> 
  slice_head(n = 3)

frequency <- filtered_speeches |> 
  group_by(president) |> 
  count(word) |> 
  mutate(proportion = n / sum(n)) |> 
  ungroup() |> 
  select(-n) |> 
  pivot_wider(names_from = president, 
              values_from = proportion) |> 
  mutate(avg_proportion = rowMeans(across(c("Barroso", "Juncker", "von der Leyen")), 
                                   na.rm = TRUE)) |>
  arrange(desc(avg_proportion))
frequency

# Correlation?
```

### Wordcloud

```{r}
filtered_speeches |> 
  count(word, sort = TRUE) |> 
  with(wordcloud(word, n, colors = brewer.pal(4, "Accent"), max.words = 100))
# change color palette

filtered_speeches |> 
  filter(!word %in% c("european", "europe", "eu", "union", "commision")) |>
  count(word, sort = TRUE) |> 
  filter(n > 60) |> 
  with(wordcloud(word, n, colors = brewer.pal(4, "Accent")))
```


## Sentiment analysis

```{r}
get_sentiments("afinn")
get_sentiments("nrc")
get_sentiments("bing")
```

```{r}
# Most common negative words by bing
filtered_speeches |> 
  left_join(get_sentiments("bing"), by = join_by(word)) |> 
  filter(sentiment == "negative") |> 
  count(word, sort = TRUE) |> 
  slice_head(n = 10)

# Most common positive words by bing
filtered_speeches |> 
  left_join(get_sentiments("bing"), by = join_by(word)) |> 
  filter(sentiment == "positive") |> 
  count(word, sort = TRUE) |> 
  slice_head(n = 10)

# Trust
nrc_trust <- get_sentiments("nrc") |> 
  filter(sentiment == "trust")
filtered_speeches |> 
  left_join(nrc_trust, by = join_by(word)) |> 
  filter(sentiment == "trust") |> 
  count(word, sort = TRUE) |> 
  slice_head(n = 10)

# Fear
nrc_fear <- get_sentiments("nrc") |> 
  filter(sentiment == "fear")
filtered_speeches |> 
  left_join(nrc_fear, by = join_by(word)) |> 
  filter(sentiment == "fear") |> 
  count(word, sort = TRUE) |> 
  slice_head(n = 10)

# Sadness
nrc_sadness <- get_sentiments("nrc") |> 
  filter(sentiment == "sadness")
filtered_speeches |> 
  left_join(nrc_sadness, by = join_by(word)) |> 
  filter(sentiment == "sadness") |> 
  count(word, sort = TRUE) |> 
  slice_head(n = 10)

# Anger
nrc_anger <- get_sentiments("nrc") |> 
  filter(sentiment == "anger")
filtered_speeches |> 
  left_join(nrc_anger, by = join_by(word)) |> 
  filter(sentiment == "anger") |> 
  count(word, sort = TRUE) |> 
  slice_head(n = 10)

# Surprise
nrc_surprise <- get_sentiments("nrc") |> 
  filter(sentiment == "surprise")
filtered_speeches |> 
  left_join(nrc_surprise, by = join_by(word)) |> 
  filter(sentiment == "surprise") |> 
  count(word, sort = TRUE) |> 
  slice_head(n = 10)

# Disgust
nrc_disgust <- get_sentiments("nrc") |> 
  filter(sentiment == "disgust")
filtered_speeches |> 
  left_join(nrc_disgust, by = join_by(word)) |> 
  filter(sentiment == "disgust") |> 
  count(word, sort = TRUE) |> 
  slice_head(n = 10)

# Joy
nrc_joy <- get_sentiments("nrc") |> 
  filter(sentiment == "joy")
filtered_speeches |> 
  left_join(nrc_joy, by = join_by(word)) |> 
  filter(sentiment == "joy") |> 
  count(word, sort = TRUE) |> 
  slice_head(n = 10)

# Anticipation
nrc_anticipation <- get_sentiments("nrc") |> 
  filter(sentiment == "anticipation")
filtered_speeches |> 
  left_join(nrc_anticipation, by = join_by(word)) |> 
  filter(sentiment == "anticipation") |> 
  count(word, sort = TRUE) |> 
  slice_head(n = 10)
```

Do the speeches have a similar structure related to poisitivity and negativity?

```{r}
sentiment_chuncks <- filtered_speeches |>
  mutate(year = as.factor(year)) |> 
  group_by(year) |>
  mutate(word_id = row_number(),
         chunk = (word_id %/% 100) + 1) |> 
  select(-word_id) |> 
  left_join(get_sentiments("afinn"), by = "word") |>
  group_by(year, chunk) |>                        
  summarise(sentiment = sum(value, na.rm = TRUE),
            .groups = "drop")

ggplot(sentiment_chuncks, aes(x = chunk, y = sentiment, fill = year)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ year, ncol = 2, scales = "free_x")


sentiment_chuncks <- filtered_speeches |>
  mutate(year = as.factor(year)) |> 
  group_by(year) |>
  mutate(word_id = row_number(),
         chunk = (word_id %/% 100) + 1) |> 
  select(-word_id) |> 
  left_join(get_sentiments("bing"), by = "word") |>
  group_by(year, chunk) |>
  count(sentiment) |> 
  pivot_wider(names_from = sentiment, 
              values_from = n, values_fill = 0) |>
  select(-"NA") |> 
  mutate(sentiment = positive - negative)

ggplot(sentiment_chuncks, aes(x = chunk, y = sentiment, fill = year)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ year, ncol = 2, scales = "free_x")
```

## TF-IDF

```{r}
# Do not remove stopwords
speeches_tf_idf <- filtered_speeches |> 
  count(year, word, sort = TRUE) |> 
  bind_tf_idf(term = word, document = year, n = n)

speeches_tf_idf |>
  arrange(desc(tf_idf))

speeches_tf_idf |> 
  group_by(year) |> 
  slice_max(tf_idf)

speeches_tf_idf |> 
  mutate(president = case_when(
    year %in% c(2010, 2011, 2012, 2013) ~ "Barroso",
    year %in% c(2015, 2016, 2017, 2018) ~ "Juncker",
    year %in% c(2020, 2021, 2022, 2023) ~ "von der Leyen")) |>
  group_by(president) |> 
  slice_max(tf_idf, n = 10)



# Deleting some more words?
```

Zipfâ€™s law as well?

Look at specific words over time? 

Key words in context? creating a corpus object then using kwic to see why some of the weird words with high tf-idf are used in those particular years

Stemming/lemmatizing? for counting words/tf-idf

## Bigrams

```{r}
# Keeping all bigrams that are not 2 stopwords
speeches_bigrams <- speeches |> 
  unnest_tokens(bigram, text, token = "ngrams", n = 2) |> 
  separate(bigram, c("word1", "word2"), sep = " ") |>
  filter(!(word1 %in% stop_words$word & word2 %in% stop_words$word))

# Keeping only those where neither is a stopword
speeches_bigrams <- speeches |> 
  unnest_tokens(bigram, text, token = "ngrams", n = 2) |> 
  separate(bigram, c("word1", "word2"), sep = " ") |>
  filter(!word1 %in% stop_words$word,
         !word2 %in% stop_words$word) |> 
  unite("bigram", "word1", "word2", sep = " ")

# Which one should I use?
```


```{r}
speeches_bigrams |> 
  count(bigram, sort = TRUE)
```


```{r}
bigrams_tf_idf <- speeches_bigrams |> 
  count(year, bigram, sort = TRUE) |> 
  bind_tf_idf(term = bigram, document = year, n = n) |> 
  arrange(desc(tf_idf))
```


Correlation?

Conditional n-grams?

Use bigrams to see biases in sentiment analysis?

## Trigrams

```{r}
speeches_trigrams <- speeches |> 
  unnest_tokens(bigram, text, token = "ngrams", n = 3)
```

## Sparsity

```{r}
speeches_dtm <- filtered_speeches |>
  # Counting the appearances of each word in each speech
  count(year, word, sort = TRUE) |>
  # Transforming from tidy format to document-term-matrix
  cast_dtm(document = year, term = word, value = n)

speeches_dtm
```

12 speeches containing a total of 5593 different (non-stop)words. 79% percent of sparsity in our document-term matrix means that 79% of the cells in the matrix are zeros. 79% of the word-document combinations do not happen in the speeches that we have analyzed. While this sparsity might seem high, sparsity can even be much higher in other real word text data (>90/95%). In our case, the sparsity is somewhat lower because these are political speeches made by the same institution (for several years represented by the same person), in the same context and that therefore often revolve around recurring topics. This thematic consistency reduces the number of unique, non-overlapping words across documents, making the vocabulary of the speeches across the years similar and in turn, it lowers the overall sparsity of our collection. Another factor that makes our sparsity lower is the fact that we are analyzing a relatively small number of documents (12 speeches). In larger collections, the sparsity tends to increase as the number of documents increases carrying with them new unique words.

## Topic modelling

```{r}
# Applying LDA with 5 topics
lda_speeches <- LDA(speeches_dtm, k = 4, control = list(seed = 777))

# Extracting the most likely terms to belong to each topic
terms(lda_speeches, k = 10)
```

As can be seen from the results above, most of the top terms are common across all topics. This is probably due to the fact that these are also the most frequent words in the speeches and thus can be found in all topics. To improve this situation I will get rid of them by building a custom stop words list.

```{r}
# Custom stop words
stop_custom <- tibble(word = c("european", 
                               "europe", 
                               "eu", 
                               "union", 
                               "commission", 
                               "honourable",
                               "world",
                               "people",
                               "time",
                               "future"))

# Repeating the pre-processing steps
tidy_speeches <- speeches |>
  unnest_tokens(word, text) |>
  anti_join(stop_words, by = join_by(word)) |>
  anti_join(stop_custom, by = join_by(word)) |>
  count(year, word, sort = TRUE) |>
  arrange(desc(n))

speeches_dtm <- tidy_speeches |>
  cast_dtm(document = year, term = word, value = n)

lda_speeches <- LDA(speeches_dtm, k = 4, control = list(seed = 777))

terms(lda_speeches, k = 15)
topics <- topics(lda_speeches)
topics[order(names(topics))]
```

Our analysis is way better now. From the results of topic modelling it can be seen that for the Barroso presidency from 2010 to 2013, as well as for the first of Juncker's speeches in 2015, the main topic seems to be the economic and financial crisis related with the global financial crisis and the subsequent eurozone crisis. Topic n.2 is related with the pandemic (ex. digital, nextgenerationeu), as well as with Ukraine's war (ex. ukraine, energy). Topic n.2 is prevalent in 2020 and 2022, the first speeches after each of these 2 crisis unfolded. Topic n.3 is related mainly with elections, a newly found unity and defense of the rule of law and democracy. These are all topics relevant in 2017 and 2018 when the EU had come to terms with the fact that Brexit was happening and EU commission president Juncker was trying to set out a vision for the future of the post-Brexit European Union. At the same time that he was praising and highlighting the unity and commitment of the remaining EU countries, he was also warning against the worsening of the democratic conditions in some of the European states and the need to defend the rule of law, thus underlining the importance of the forthcoming 2019 European elections. Topic n.4 is probably the more general topic, grouping together several of what have been key priorities of the European Commission in the last decade. These are speeches that come at times of difficulties for the Union, but without being necessarily in the most acute part of a crisis (2016, 2021, 2023). Some of the priorities mentioned by the EU commission presidents range from global challenges such as climate change, to the need to defend the rule of law and the EU's values, to the need to invest to create jobs and have a functioning common market for EU companies. Important in these 2016, 2021 and 2023 speeches is also the concept of security which has been declined in increasingly more ways. Initially related to migrants and terrorism in 2016, the concept then expanded into an umbrella term covering also social and economic security, turning into a key priority and concept of the von der Leyen's Commission. 
